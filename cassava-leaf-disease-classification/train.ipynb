{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import albumentations as albu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from utils.models import EffNetMSD\n",
    "from utils.loss import FocalCosineLoss, focal_loss\n",
    "from utils.trainer import NNTrainer\n",
    "from utils.data import MyDataset, get_train_transforms, get_valid_transforms\n",
    "\n",
    "import efficientnet_pytorch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# \"0\": \"Cassava Bacterial Blight (CBB)\", \n",
    "# \"1\": \"Cassava Brown Streak Disease (CBSD)\", \n",
    "# \"2\": \"Cassava Green Mottle (CGM)\", \n",
    "# \"3\": \"Cassava Mosaic Disease (CMD)\", \n",
    "# \"4\": \"Healthy\"\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'model_name' : 'efficientnet-b5', #'resnext50_32x4d',#'resnext101_32x8d', #'resnext50_32x4d', #'efficientnet-b3',\n",
    "       'advprop' : False,\n",
    "       'seed' : 256,\n",
    "       'img_size' : 512,\n",
    "       'batch_size' : 4,\n",
    "       'accum_steps' : 1,\n",
    "       'n_epoch' : 15,\n",
    "       'patience' : 3,\n",
    "       'n_dropouts' : 30,\n",
    "       'tta' : None,\n",
    "       'lr' : 2e-4,\n",
    "       'weight_decay' : 0, # 1e-6,\n",
    "       'extra_data' : True,\n",
    "       'extra_data_unsepervised' : False,\n",
    "       'sample_coeffs' : {0:4, 1:2.5, 2:2.5, 3:1, 4:2.5},\n",
    "       'fullsampling' : None, #True,\n",
    "       \n",
    "       'optim' : Adam,\n",
    "\n",
    "       #loss, weighted = lambda x, y: focal_loss(x, y), False\n",
    "       #loss, weighted = torch.nn.CrossEntropyLoss, True\n",
    "       'loss' : FocalCosineLoss(),\n",
    "#       'loss' : lambda x, y: focal_loss(x, y),\n",
    "       \n",
    "       'weighted' : False,\n",
    "       \n",
    "       'scheduler' : lambda x : CosineAnnealingWarmRestarts(x, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1),\n",
    "        \n",
    "       'random_state' : 123,\n",
    "\n",
    "       'device' : 'cuda',\n",
    "}\n",
    "\n",
    "cfg['augmentations_train'] = get_train_transforms\n",
    "cfg['augmentations_test'] = cfg['augmentations_train'] #get_valid_transforms(cfg['img_size']), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "path2 = './add_data'\n",
    "path_train = f'{path}/train_images/'\n",
    "path_dct = {0 : f'{path2}/train/cbb/',\n",
    "            1 : f'{path2}/train/cbsd/',\n",
    "            2 : f'{path2}/train/cgm/',\n",
    "            3 : f'{path2}/train/cmd/',\n",
    "            4 : f'{path2}/train/healthy/'}\n",
    "path_extra = f'{path2}/extraimages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(cfg['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df[(df['image_id'] != '3551135685.jpg')&(df['image_id'] != '2252529694.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('pl_df.csv')\n",
    "df2 = df2[['image_id', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=cfg['random_state'])\n",
    "splits = skf.split(df.image_id, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "    model = EffNetMSD(net=cfg[\"model_name\"], advprop=cfg['advprop'], n_dropouts=cfg['n_dropouts'])\n",
    "    old_model = './models_pl/eff5_2/efficientnet-b5_split_0_best_.pth'\n",
    "    model.load_state_dict(torch.load(old_model, map_location=cfg['device']))\n",
    "    \n",
    "    if False:  #'efficientnet' in cfg[\"model_name\"]:\n",
    "        for name, param in model.named_parameters():\n",
    "            if '_bn' in name:\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "    else:        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    if not cfg['extra_data']:\n",
    "        path_dct=None\n",
    "        \n",
    "    train_dataset = MyDataset(train_df=df, train_idx=train_idx, train_path=path_train,\\\n",
    "                              train_df2=df2, train_path2=path_extra, img_size=cfg['img_size'],\\\n",
    "                              augmentations=cfg['augmentations_train'](cfg['img_size']),\\\n",
    "                              path_dct=path_dct, shuffle=cfg['random_state'], advprop=cfg['advprop'],\\\n",
    "                              sample_coeffs=cfg['sample_coeffs'], fullsampling=cfg['fullsampling'])\n",
    "    \n",
    "    valid_dataset = MyDataset(train_df=df, train_idx=valid_idx, train_path=path_train, img_size=cfg['img_size'],\\\n",
    "                              augmentations=cfg['augmentations_test'](cfg['img_size']),\\\n",
    "                              shuffle=cfg['random_state'], advprop=cfg['advprop'], tta=cfg['tta'])\n",
    "    extra_dataset = MyDataset(path_extra=path_extra, path_extra2=None, img_size=cfg['img_size'],\\\n",
    "                              augmentations=cfg['augmentations_train'](cfg['img_size']),\\\n",
    "                              augmentations2=cfg['augmentations_test'](cfg['img_size']),\\\n",
    "                              shuffle=cfg['random_state'], advprop=cfg['advprop'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg['batch_size'], drop_last=False, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=cfg['batch_size'], drop_last=False, shuffle=False)\n",
    "    if cfg['extra_data_unsepervised']:\n",
    "        extra_loader = DataLoader(extra_dataset, batch_size=cfg['batch_size'], drop_last=False, shuffle=True)\n",
    "    else:\n",
    "        extra_loader = None\n",
    "    \n",
    "    trainer = NNTrainer(model, device=cfg['device'], label_names=[0, 1, 2, 3, 4], model_name=f'{cfg[\"model_name\"]}_split_{i}')\n",
    "    metric = trainer.train(train_loader=train_loader, val_loader=valid_loader, extra_loader=extra_loader,\\\n",
    "                  n_epoch=cfg['n_epoch'], optim=cfg['optim'], weight_decay=cfg['weight_decay'], schedul=cfg['scheduler'],\\\n",
    "                  loss=cfg['loss'], weighted=cfg['weighted'], lr=cfg['lr'], accum_steps=cfg['accum_steps'], show_results=True,\\\n",
    "                  saved_models_dir='./models/', verbose=True, patience=cfg['patience'], calc_metric_batch=None)\n",
    "    \n",
    "    metrics.append(metric)\n",
    "    print('best metrics:', metrics)\n",
    "    print('mean best metrics:', np.mean(metrics))\n",
    "    \n",
    "    model.to('cpu')\n",
    "\n",
    "    del trainer\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
